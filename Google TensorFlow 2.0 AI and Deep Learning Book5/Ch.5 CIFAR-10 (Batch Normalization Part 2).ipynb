{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from preprocessing import parse_aug_fn, parse_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = tfds.load('cifar10', split='train[:10%]')\n",
    "\n",
    "train_data, info = tfds.load('cifar10', split='train[10%:100%]', with_info=True)\n",
    "\n",
    "test_data = tfds.load('cifar10', split=tfds.Split.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "batch_size = 64\n",
    "train_num = int(info.splits['train'].num_examples / 10) * 9\n",
    "\n",
    "train_data = train_data.shuffle(train_num)\n",
    "train_data = train_data.map(map_func=parse_aug_fn, num_parallel_calls=AUTOTUNE)\n",
    "train_data = train_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "valid_data = valid_data.map(map_func=parse_aug_fn, num_parallel_calls=AUTOTUNE)\n",
    "valid_data = valid_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_data = test_data.map(map_func=parse_aug_fn, num_parallel_calls=AUTOTUNE)\n",
    "test_data = test_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model-4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 30, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 13, 13, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 128)         295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 64)          73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                200768    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 943,882\n",
      "Trainable params: 942,474\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3))(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Conv2D(128, (3, 3))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(256, (3, 3))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(128, (3, 3))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(64, (3, 3))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_4 = keras.Model(inputs, outputs, name='model-4')\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'lab5-logs\\\\models\\\\'\n",
    "\n",
    "log_dir = os.path.join('lab5-logs', 'run-4-batchnormalization')\n",
    "\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '\\\\run-4-best-model.h5', monitor='val_categorical_accuracy',\n",
    "                                             save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(keras.optimizers.Adam(), loss=keras.losses.CategoricalCrossentropy(), metrics=[keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "704/704 [==============================] - 74s 105ms/step - loss: 1.5352 - categorical_accuracy: 0.4542 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 99s 141ms/step - loss: 1.3716 - categorical_accuracy: 0.5198 - val_loss: 1.4357 - val_categorical_accuracy: 0.5038\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 117s 166ms/step - loss: 1.2730 - categorical_accuracy: 0.5542 - val_loss: 1.2169 - val_categorical_accuracy: 0.5742\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 118s 167ms/step - loss: 1.1992 - categorical_accuracy: 0.5843 - val_loss: 1.7570 - val_categorical_accuracy: 0.4472\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 120s 171ms/step - loss: 1.1336 - categorical_accuracy: 0.6105 - val_loss: 1.4032 - val_categorical_accuracy: 0.5096\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 122s 173ms/step - loss: 1.0874 - categorical_accuracy: 0.6274 - val_loss: 1.4019 - val_categorical_accuracy: 0.5284\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 122s 173ms/step - loss: 1.0510 - categorical_accuracy: 0.6398 - val_loss: 1.0859 - val_categorical_accuracy: 0.6228\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 122s 173ms/step - loss: 1.0062 - categorical_accuracy: 0.6570 - val_loss: 2.3927 - val_categorical_accuracy: 0.4070\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 122s 173ms/step - loss: 0.9788 - categorical_accuracy: 0.6674 - val_loss: 1.8819 - val_categorical_accuracy: 0.4774\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 123s 174ms/step - loss: 0.9486 - categorical_accuracy: 0.6793 - val_loss: 1.2113 - val_categorical_accuracy: 0.5858\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 124s 176ms/step - loss: 0.9190 - categorical_accuracy: 0.6875 - val_loss: 1.0057 - val_categorical_accuracy: 0.6498\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 124s 176ms/step - loss: 0.8876 - categorical_accuracy: 0.7015 - val_loss: 0.9633 - val_categorical_accuracy: 0.6564\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 123s 175ms/step - loss: 0.8744 - categorical_accuracy: 0.7063 - val_loss: 0.9525 - val_categorical_accuracy: 0.6670\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 123s 175ms/step - loss: 0.8468 - categorical_accuracy: 0.7160 - val_loss: 1.0439 - val_categorical_accuracy: 0.6334\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 123s 175ms/step - loss: 0.8222 - categorical_accuracy: 0.7244 - val_loss: 1.0645 - val_categorical_accuracy: 0.6350\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 148s 210ms/step - loss: 0.7990 - categorical_accuracy: 0.7322 - val_loss: 1.0584 - val_categorical_accuracy: 0.6490\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 145s 206ms/step - loss: 0.7891 - categorical_accuracy: 0.7348 - val_loss: 0.9659 - val_categorical_accuracy: 0.6784\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 175s 249ms/step - loss: 0.7761 - categorical_accuracy: 0.7392 - val_loss: 2.1291 - val_categorical_accuracy: 0.4790\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 198s 281ms/step - loss: 0.7600 - categorical_accuracy: 0.7438 - val_loss: 0.9342 - val_categorical_accuracy: 0.6998\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 148s 211ms/step - loss: 0.7520 - categorical_accuracy: 0.7493 - val_loss: 0.8622 - val_categorical_accuracy: 0.7026\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 201s 285ms/step - loss: 0.7293 - categorical_accuracy: 0.7558 - val_loss: 0.8097 - val_categorical_accuracy: 0.7126\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 208s 295ms/step - loss: 0.7221 - categorical_accuracy: 0.7603 - val_loss: 0.8573 - val_categorical_accuracy: 0.7106\n",
      "Epoch 23/100\n",
      "704/704 [==============================] - 159s 226ms/step - loss: 0.7077 - categorical_accuracy: 0.7671 - val_loss: 0.9191 - val_categorical_accuracy: 0.6984\n",
      "Epoch 24/100\n",
      "704/704 [==============================] - 193s 274ms/step - loss: 0.6992 - categorical_accuracy: 0.7686 - val_loss: 1.2214 - val_categorical_accuracy: 0.6264\n",
      "Epoch 25/100\n",
      "704/704 [==============================] - 138s 195ms/step - loss: 0.6851 - categorical_accuracy: 0.7725 - val_loss: 0.8205 - val_categorical_accuracy: 0.7292\n",
      "Epoch 26/100\n",
      "704/704 [==============================] - 231s 329ms/step - loss: 0.6849 - categorical_accuracy: 0.7737 - val_loss: 0.9028 - val_categorical_accuracy: 0.6992\n",
      "Epoch 27/100\n",
      "704/704 [==============================] - 135s 192ms/step - loss: 0.6727 - categorical_accuracy: 0.7782 - val_loss: 0.7489 - val_categorical_accuracy: 0.7442\n",
      "Epoch 28/100\n",
      "704/704 [==============================] - 137s 195ms/step - loss: 0.6608 - categorical_accuracy: 0.7814 - val_loss: 1.3459 - val_categorical_accuracy: 0.6190\n",
      "Epoch 29/100\n",
      "704/704 [==============================] - 122s 173ms/step - loss: 0.6602 - categorical_accuracy: 0.7829 - val_loss: 0.7456 - val_categorical_accuracy: 0.7478\n",
      "Epoch 30/100\n",
      "704/704 [==============================] - 135s 192ms/step - loss: 0.6436 - categorical_accuracy: 0.7871 - val_loss: 1.3438 - val_categorical_accuracy: 0.6198\n",
      "Epoch 31/100\n",
      "704/704 [==============================] - 122s 174ms/step - loss: 0.6358 - categorical_accuracy: 0.7878 - val_loss: 1.0208 - val_categorical_accuracy: 0.6916\n",
      "Epoch 32/100\n",
      "704/704 [==============================] - 139s 197ms/step - loss: 0.6303 - categorical_accuracy: 0.7909 - val_loss: 0.7966 - val_categorical_accuracy: 0.7332\n",
      "Epoch 33/100\n",
      "704/704 [==============================] - 122s 174ms/step - loss: 0.6106 - categorical_accuracy: 0.8002 - val_loss: 0.9020 - val_categorical_accuracy: 0.7078\n",
      "Epoch 34/100\n",
      "704/704 [==============================] - 139s 198ms/step - loss: 0.6201 - categorical_accuracy: 0.7964 - val_loss: 1.8969 - val_categorical_accuracy: 0.5286\n",
      "Epoch 35/100\n",
      "704/704 [==============================] - 122s 174ms/step - loss: 0.6102 - categorical_accuracy: 0.7975 - val_loss: 0.7162 - val_categorical_accuracy: 0.7604\n",
      "Epoch 36/100\n",
      "704/704 [==============================] - 172s 245ms/step - loss: 0.6048 - categorical_accuracy: 0.7993 - val_loss: 0.7524 - val_categorical_accuracy: 0.7486\n",
      "Epoch 37/100\n",
      "704/704 [==============================] - 182s 258ms/step - loss: 0.5878 - categorical_accuracy: 0.8065 - val_loss: 0.7151 - val_categorical_accuracy: 0.7622\n",
      "Epoch 38/100\n",
      "704/704 [==============================] - 145s 206ms/step - loss: 0.5825 - categorical_accuracy: 0.8077 - val_loss: 1.2097 - val_categorical_accuracy: 0.6518\n",
      "Epoch 39/100\n",
      "704/704 [==============================] - 181s 257ms/step - loss: 0.5914 - categorical_accuracy: 0.8056 - val_loss: 0.8081 - val_categorical_accuracy: 0.7320\n",
      "Epoch 40/100\n",
      "704/704 [==============================] - 167s 237ms/step - loss: 0.5778 - categorical_accuracy: 0.8089 - val_loss: 0.8354 - val_categorical_accuracy: 0.7206\n",
      "Epoch 41/100\n",
      "704/704 [==============================] - 152s 216ms/step - loss: 0.5724 - categorical_accuracy: 0.8127 - val_loss: 0.8764 - val_categorical_accuracy: 0.7192\n",
      "Epoch 42/100\n",
      "704/704 [==============================] - 135s 192ms/step - loss: 0.5774 - categorical_accuracy: 0.8112 - val_loss: 0.7310 - val_categorical_accuracy: 0.7548\n",
      "Epoch 43/100\n",
      "704/704 [==============================] - 152s 216ms/step - loss: 0.5685 - categorical_accuracy: 0.8138 - val_loss: 0.8043 - val_categorical_accuracy: 0.7338\n",
      "Epoch 44/100\n",
      "704/704 [==============================] - 174s 246ms/step - loss: 0.5582 - categorical_accuracy: 0.8158 - val_loss: 1.1571 - val_categorical_accuracy: 0.6690\n",
      "Epoch 45/100\n",
      "704/704 [==============================] - 146s 207ms/step - loss: 0.5562 - categorical_accuracy: 0.8168 - val_loss: 0.7497 - val_categorical_accuracy: 0.7494\n",
      "Epoch 46/100\n",
      "704/704 [==============================] - 166s 236ms/step - loss: 0.5399 - categorical_accuracy: 0.8219 - val_loss: 0.7222 - val_categorical_accuracy: 0.7590\n",
      "Epoch 47/100\n",
      "704/704 [==============================] - 150s 213ms/step - loss: 0.5520 - categorical_accuracy: 0.8208 - val_loss: 0.8004 - val_categorical_accuracy: 0.7494\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 157s 224ms/step - loss: 0.5458 - categorical_accuracy: 0.8216 - val_loss: 0.7408 - val_categorical_accuracy: 0.7574\n",
      "Epoch 49/100\n",
      "704/704 [==============================] - 148s 210ms/step - loss: 0.5354 - categorical_accuracy: 0.8249 - val_loss: 0.7153 - val_categorical_accuracy: 0.7636\n",
      "Epoch 50/100\n",
      "704/704 [==============================] - 121s 172ms/step - loss: 0.5231 - categorical_accuracy: 0.8282 - val_loss: 0.8175 - val_categorical_accuracy: 0.7428\n",
      "Epoch 51/100\n",
      "704/704 [==============================] - 121s 172ms/step - loss: 0.5276 - categorical_accuracy: 0.8291 - val_loss: 0.7419 - val_categorical_accuracy: 0.7586\n",
      "Epoch 52/100\n",
      "704/704 [==============================] - 121s 172ms/step - loss: 0.5186 - categorical_accuracy: 0.8316 - val_loss: 1.0922 - val_categorical_accuracy: 0.6842\n",
      "Epoch 53/100\n",
      "704/704 [==============================] - 121s 171ms/step - loss: 0.5255 - categorical_accuracy: 0.8267 - val_loss: 0.8016 - val_categorical_accuracy: 0.7436\n",
      "Epoch 54/100\n",
      "704/704 [==============================] - 122s 173ms/step - loss: 0.5185 - categorical_accuracy: 0.8301 - val_loss: 0.6807 - val_categorical_accuracy: 0.7776\n",
      "Epoch 55/100\n",
      "704/704 [==============================] - 133s 189ms/step - loss: 0.5120 - categorical_accuracy: 0.8350 - val_loss: 0.6979 - val_categorical_accuracy: 0.7714\n",
      "Epoch 56/100\n",
      "704/704 [==============================] - 122s 173ms/step - loss: 0.5162 - categorical_accuracy: 0.8316 - val_loss: 0.6703 - val_categorical_accuracy: 0.7672\n",
      "Epoch 57/100\n",
      "704/704 [==============================] - 122s 174ms/step - loss: 0.5153 - categorical_accuracy: 0.8334 - val_loss: 0.8444 - val_categorical_accuracy: 0.7292\n",
      "Epoch 58/100\n",
      "704/704 [==============================] - 123s 174ms/step - loss: 0.5062 - categorical_accuracy: 0.8339 - val_loss: 0.6507 - val_categorical_accuracy: 0.7846\n",
      "Epoch 59/100\n",
      "704/704 [==============================] - 123s 174ms/step - loss: 0.5045 - categorical_accuracy: 0.8349 - val_loss: 0.7362 - val_categorical_accuracy: 0.7662\n",
      "Epoch 60/100\n",
      "704/704 [==============================] - 146s 208ms/step - loss: 0.4918 - categorical_accuracy: 0.8400 - val_loss: 0.6273 - val_categorical_accuracy: 0.7980\n",
      "Epoch 61/100\n",
      "704/704 [==============================] - 154s 219ms/step - loss: 0.4952 - categorical_accuracy: 0.8383 - val_loss: 0.7049 - val_categorical_accuracy: 0.7678\n",
      "Epoch 62/100\n",
      "704/704 [==============================] - 121s 171ms/step - loss: 0.4880 - categorical_accuracy: 0.8414 - val_loss: 0.7473 - val_categorical_accuracy: 0.7630\n",
      "Epoch 63/100\n",
      "704/704 [==============================] - 152s 216ms/step - loss: 0.4935 - categorical_accuracy: 0.8404 - val_loss: 0.6203 - val_categorical_accuracy: 0.7944\n",
      "Epoch 64/100\n",
      "704/704 [==============================] - 156s 222ms/step - loss: 0.4865 - categorical_accuracy: 0.8429 - val_loss: 0.8978 - val_categorical_accuracy: 0.7240\n",
      "Epoch 65/100\n",
      "704/704 [==============================] - 121s 172ms/step - loss: 0.4782 - categorical_accuracy: 0.8435 - val_loss: 0.7075 - val_categorical_accuracy: 0.7772\n",
      "Epoch 66/100\n",
      "704/704 [==============================] - 121s 172ms/step - loss: 0.4776 - categorical_accuracy: 0.8448 - val_loss: 0.6207 - val_categorical_accuracy: 0.7944\n",
      "Epoch 67/100\n",
      "704/704 [==============================] - 121s 172ms/step - loss: 0.4739 - categorical_accuracy: 0.8437 - val_loss: 0.6092 - val_categorical_accuracy: 0.8076\n",
      "Epoch 68/100\n",
      "704/704 [==============================] - 121s 172ms/step - loss: 0.4671 - categorical_accuracy: 0.8476 - val_loss: 0.7947 - val_categorical_accuracy: 0.7376\n",
      "Epoch 69/100\n",
      "704/704 [==============================] - 122s 173ms/step - loss: 0.4637 - categorical_accuracy: 0.8497 - val_loss: 0.6628 - val_categorical_accuracy: 0.7892\n",
      "Epoch 70/100\n",
      "704/704 [==============================] - 123s 175ms/step - loss: 0.4699 - categorical_accuracy: 0.8472 - val_loss: 0.6285 - val_categorical_accuracy: 0.7990\n",
      "Epoch 71/100\n",
      "704/704 [==============================] - 123s 175ms/step - loss: 0.4556 - categorical_accuracy: 0.8503 - val_loss: 0.7502 - val_categorical_accuracy: 0.7708\n",
      "Epoch 72/100\n",
      "704/704 [==============================] - 123s 175ms/step - loss: 0.4669 - categorical_accuracy: 0.8487 - val_loss: 0.6081 - val_categorical_accuracy: 0.8034\n",
      "Epoch 73/100\n",
      "704/704 [==============================] - 123s 175ms/step - loss: 0.4637 - categorical_accuracy: 0.8513 - val_loss: 0.6529 - val_categorical_accuracy: 0.7876\n",
      "Epoch 74/100\n",
      "704/704 [==============================] - 138s 197ms/step - loss: 0.4574 - categorical_accuracy: 0.8526 - val_loss: 0.7124 - val_categorical_accuracy: 0.7714\n",
      "Epoch 75/100\n",
      "704/704 [==============================] - 140s 198ms/step - loss: 0.4573 - categorical_accuracy: 0.8516 - val_loss: 0.7133 - val_categorical_accuracy: 0.7760\n",
      "Epoch 76/100\n",
      "704/704 [==============================] - 142s 201ms/step - loss: 0.4567 - categorical_accuracy: 0.8515 - val_loss: 0.7010 - val_categorical_accuracy: 0.7766\n",
      "Epoch 77/100\n",
      "704/704 [==============================] - 141s 201ms/step - loss: 0.4545 - categorical_accuracy: 0.8519 - val_loss: 0.6131 - val_categorical_accuracy: 0.7990\n",
      "Epoch 78/100\n",
      "704/704 [==============================] - 152s 216ms/step - loss: 0.4535 - categorical_accuracy: 0.8521 - val_loss: 0.7065 - val_categorical_accuracy: 0.7684\n",
      "Epoch 79/100\n",
      "704/704 [==============================] - 154s 218ms/step - loss: 0.4472 - categorical_accuracy: 0.8550 - val_loss: 0.6714 - val_categorical_accuracy: 0.7842\n",
      "Epoch 80/100\n",
      "704/704 [==============================] - 150s 213ms/step - loss: 0.4447 - categorical_accuracy: 0.8559 - val_loss: 0.6981 - val_categorical_accuracy: 0.7734\n",
      "Epoch 81/100\n",
      "704/704 [==============================] - 162s 230ms/step - loss: 0.4467 - categorical_accuracy: 0.8547 - val_loss: 0.6569 - val_categorical_accuracy: 0.7836\n",
      "Epoch 82/100\n",
      "704/704 [==============================] - 154s 219ms/step - loss: 0.4353 - categorical_accuracy: 0.8567 - val_loss: 0.6297 - val_categorical_accuracy: 0.7978\n",
      "Epoch 83/100\n",
      "704/704 [==============================] - 155s 220ms/step - loss: 0.4345 - categorical_accuracy: 0.8611 - val_loss: 0.7202 - val_categorical_accuracy: 0.7704\n",
      "Epoch 84/100\n",
      "704/704 [==============================] - 153s 217ms/step - loss: 0.4332 - categorical_accuracy: 0.8589 - val_loss: 0.6715 - val_categorical_accuracy: 0.7786\n",
      "Epoch 85/100\n",
      "704/704 [==============================] - 161s 228ms/step - loss: 0.4400 - categorical_accuracy: 0.8584 - val_loss: 0.7470 - val_categorical_accuracy: 0.7710\n",
      "Epoch 86/100\n",
      "704/704 [==============================] - 152s 215ms/step - loss: 0.4389 - categorical_accuracy: 0.8585 - val_loss: 0.7019 - val_categorical_accuracy: 0.7798\n",
      "Epoch 87/100\n",
      "704/704 [==============================] - 159s 226ms/step - loss: 0.4322 - categorical_accuracy: 0.8596 - val_loss: 0.6471 - val_categorical_accuracy: 0.7908\n",
      "Epoch 88/100\n",
      "704/704 [==============================] - 167s 237ms/step - loss: 0.4281 - categorical_accuracy: 0.8612 - val_loss: 0.5651 - val_categorical_accuracy: 0.8132\n",
      "Epoch 89/100\n",
      "704/704 [==============================] - 154s 219ms/step - loss: 0.4237 - categorical_accuracy: 0.8621 - val_loss: 0.6575 - val_categorical_accuracy: 0.7986\n",
      "Epoch 90/100\n",
      "704/704 [==============================] - 163s 232ms/step - loss: 0.4268 - categorical_accuracy: 0.8610 - val_loss: 0.6798 - val_categorical_accuracy: 0.7866\n",
      "Epoch 91/100\n",
      "704/704 [==============================] - 160s 227ms/step - loss: 0.4284 - categorical_accuracy: 0.8616 - val_loss: 0.6921 - val_categorical_accuracy: 0.7750\n",
      "Epoch 92/100\n",
      "704/704 [==============================] - 163s 231ms/step - loss: 0.4194 - categorical_accuracy: 0.8644 - val_loss: 0.5954 - val_categorical_accuracy: 0.8080\n",
      "Epoch 93/100\n",
      "704/704 [==============================] - 169s 240ms/step - loss: 0.4248 - categorical_accuracy: 0.8630 - val_loss: 0.6483 - val_categorical_accuracy: 0.7886\n",
      "Epoch 94/100\n",
      "704/704 [==============================] - 161s 229ms/step - loss: 0.4259 - categorical_accuracy: 0.8622 - val_loss: 0.6277 - val_categorical_accuracy: 0.7966\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 151s 215ms/step - loss: 0.4153 - categorical_accuracy: 0.8651 - val_loss: 0.5971 - val_categorical_accuracy: 0.8038\n",
      "Epoch 96/100\n",
      "704/704 [==============================] - 172s 244ms/step - loss: 0.4192 - categorical_accuracy: 0.8651 - val_loss: 0.6394 - val_categorical_accuracy: 0.7950\n",
      "Epoch 97/100\n",
      "704/704 [==============================] - 166s 236ms/step - loss: 0.4114 - categorical_accuracy: 0.8677 - val_loss: 0.6381 - val_categorical_accuracy: 0.7962\n",
      "Epoch 98/100\n",
      "704/704 [==============================] - 159s 227ms/step - loss: 0.4126 - categorical_accuracy: 0.8652 - val_loss: 0.7294 - val_categorical_accuracy: 0.7712\n",
      "Epoch 99/100\n",
      "704/704 [==============================] - 170s 241ms/step - loss: 0.4058 - categorical_accuracy: 0.8707 - val_loss: 0.7249 - val_categorical_accuracy: 0.7652\n",
      "Epoch 100/100\n",
      "704/704 [==============================] - 151s 214ms/step - loss: 0.4088 - categorical_accuracy: 0.8678 - val_loss: 0.7188 - val_categorical_accuracy: 0.7784\n"
     ]
    }
   ],
   "source": [
    "history_1 = model_4.fit(train_data, epochs=100, validation_data=valid_data, callbacks=[model_cbk, model_mckp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    157/Unknown - 6s 40ms/step - loss: 0.7119 - categorical_accuracy: 0.7764\n",
      "Model-4 Accuracy: 0.7764000296592712%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model_4.evaluate(test_data)\n",
    "print('\\nModel-4 Accuracy: {}%'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
